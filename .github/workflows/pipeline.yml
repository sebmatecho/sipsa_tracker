name: Run SIPSA Data Pipeline

on:
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight UTC

jobs:
  run-pipeline:
    runs-on: ubuntu-latest  # Use the latest Ubuntu runner

    steps:
    # Step 1: Check out the repository code
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Python environment
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9

    # Step 3: Install dependencies from requirements.txt
    - name: Install dependencies
      run: |
        python -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt

    # Step 4: Run the Python script (this executes main.py)
    # Use GitHub Secrets to pass environment variables securely
    - name: Run SIPSA Data Pipeline
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
        DB_HOST: ${{ secrets.DB_HOST }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_PASS: ${{ secrets.DB_PASS }}
        DB_PORT: ${{ secrets.DB_PORT }}
        DB_USER: ${{ secrets.DB_USER }}
        TABLE_NAME: ${{ secrets.TABLE_NAME }}
      run: |
        source venv/bin/activate
        python main.py

    # Optional Step 5: Upload logs or send notifications (if required)
    - name: Upload logs
      run: |
        # Upload or store logs in a location like AWS S3 (if applicable)
        echo "Logs uploaded"
